{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SQUAD_question generation",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliofortini/NLP_SQuAD_Project/blob/gpt/SQUAD_question_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYJU40qeWMJ1"
      },
      "source": [
        "# SQUAD Question Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UglnBpahmlMg"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edB8xwhnWNzJ",
        "outputId": "c3be09b1-472e-4af7-f4c8-be36321962be"
      },
      "source": [
        "import json\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "drive_path = \"/content/drive/My Drive/SQUAD/QGen/\"\r\n",
        "\r\n",
        "RANDOM_STATE = 42\r\n",
        "\r\n",
        "!pip install transformers\r\n",
        "!nvidia-smi\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import transformers\r\n",
        "from transformers import Trainer, TrainingArguments, AutoModelWithLMHead, AutoTokenizer\r\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling\r\n",
        "from transformers import pipeline\r\n",
        "\r\n",
        "import time\r\n",
        "\r\n",
        "\r\n",
        "PRETRAINED = \"gpt2\"\r\n",
        "\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED)\r\n",
        "model = AutoModelWithLMHead.from_pretrained(PRETRAINED)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Thu Feb 25 15:21:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:970: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA7HU1_fWzpn"
      },
      "source": [
        "try:\r\n",
        "  with open('training_set.json') as f:\r\n",
        "    json_data = json.load(f)\r\n",
        "except:\r\n",
        "  with open('/content/drive/My Drive/SQUAD/training_set.json') as f:\r\n",
        "    json_data = json.load(f)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trL1EscQmOnG"
      },
      "source": [
        "##Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dXbujCspB9q"
      },
      "source": [
        "MODEL_NAME = \"GTP2_SQUAD_QGEN_3\"\r\n",
        "EPOCHS = 3\r\n",
        "DATASET_LIMIT = None\r\n",
        "LOAD_FROM_DRIVE = True\r\n",
        "N_CONTEXT_GEN = None           # number of contexts to use. Choose None to take al the context in the test set\r\n",
        "QUESTIONS_PER_CONTEXT = 5     # how many question generate for each context. "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A23pEgzInJLM"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc6-zf6cV4e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "fa39cc55-30fe-4d08-e1b9-e7df3418a2db"
      },
      "source": [
        "# Creates DataFrames with useful columns by unpacking 'paragraphs' column\r\n",
        "def preprocess_df(df):\r\n",
        "  temp = []\r\n",
        "  title_dict = {}\r\n",
        "  contexts = []\r\n",
        "\r\n",
        "  for i, row in df.iterrows():\r\n",
        "    for context in row['paragraphs']:\r\n",
        "      contexts.append(context['context'])\r\n",
        "      for qa in context['qas']:\r\n",
        "        question_id = qa['id']\r\n",
        "        question = qa['question']\r\n",
        "        for answer in qa['answers']:\r\n",
        "          answer_text = answer['text']\r\n",
        "          answer_start = answer['answer_start']\r\n",
        "          answer_end = answer_start+len(answer_text)\r\n",
        "          temp.append([question_id, question, answer_text, answer_start, answer_end, i, len(contexts)-1])\r\n",
        "\r\n",
        "  context_dict = dict(enumerate(contexts))\r\n",
        "  df = pd.DataFrame(temp, columns=['question_id', 'question_text', 'answer_text', 'answer_start', 'answer_end', 'title_id', 'context_id'])\r\n",
        "  \r\n",
        "  return df, context_dict\r\n",
        "\r\n",
        "# Read data from json\r\n",
        "data = pd.json_normalize(json_data['data'])\r\n",
        "data = data\r\n",
        "\r\n",
        "# Split train and test\r\n",
        "train, val_test  = train_test_split(data, test_size=0.15, random_state=RANDOM_STATE)\r\n",
        "val, test        = train_test_split(val_test, test_size=0.01, random_state=RANDOM_STATE)\r\n",
        "\r\n",
        "# Create DataFrames with useful columns\r\n",
        "train_df, train_context_dict = preprocess_df(train)\r\n",
        "val_df, val_context_dict = preprocess_df(val)\r\n",
        "test_df, test_context_dict = preprocess_df(test)\r\n",
        "\r\n",
        "train_df = train_df[[\"context_id\", \"question_text\", \"answer_text\"]]\r\n",
        "val_df = val_df[[\"context_id\", \"question_text\", \"answer_text\"]]\r\n",
        "test_df = test_df[[\"context_id\", \"question_text\", \"answer_text\"]]\r\n",
        "\r\n",
        "print(f\"Train samples:\\t{len(train_df)}\\nVal samples:\\t{len(val_df)}\\nTest samples:\\t{len(test_df)}\")\r\n",
        "train_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train samples:\t74520\n",
            "Val samples:\t12898\n",
            "Test samples:\t181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What type of stimuli causes pain?</td>\n",
              "      <td>intense or damaging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>What type of feeling is pain?</td>\n",
              "      <td>distressing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Why has defining pain been a challenge?</td>\n",
              "      <td>complex, subjective phenomenon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>What organization's definition is widely used?</td>\n",
              "      <td>The International Association for the Study of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>In medical diagnosis, what is pain considered?</td>\n",
              "      <td>a symptom</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   context_id  ...                                        answer_text\n",
              "0           0  ...                                intense or damaging\n",
              "1           0  ...                                        distressing\n",
              "2           0  ...                     complex, subjective phenomenon\n",
              "3           0  ...  The International Association for the Study of...\n",
              "4           0  ...                                          a symptom\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xd9RSOUYH0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51baee44-371c-4b4b-9a59-837e1f469f57"
      },
      "source": [
        "def create_samples(df, context_dict, name):\r\n",
        "  samples = []\r\n",
        "  print(f\"Creating {name}.txt...\", end=\"\")\r\n",
        "  with open(f\"{drive_path}{name}_samples.txt\", \"w\") as out_file:\r\n",
        "    for i, row in df.iterrows():\r\n",
        "      context = context_dict[row[\"context_id\"]].replace(\"\\n\", \" \")\r\n",
        "      line = f\"[CTX] {context} [QS] {row['question_text']} [QE]\\n\"\r\n",
        "      out_file.write(line)\r\n",
        "      samples.append(line)\r\n",
        "    print(\"done\")\r\n",
        "  return samples\r\n",
        "\r\n",
        "\r\n",
        "train_samples = create_samples(train_df[:DATASET_LIMIT], train_context_dict, \"train\")\r\n",
        "val_samples = create_samples(val_df[:DATASET_LIMIT], val_context_dict, \"val\")\r\n",
        "test_samples = create_samples(test_df[:DATASET_LIMIT], test_context_dict, \"test\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating train.txt...done\n",
            "Creating val.txt...done\n",
            "Creating test.txt...done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_M9CLakc-6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e62ba7-d927-447b-9496-9ca515fba70a"
      },
      "source": [
        "print(\"\\nTRAIN samples: \", end=\"\")\r\n",
        "with open(drive_path + \"train_samples.txt\") as f:\r\n",
        "  train_samples = f.readlines()\r\n",
        "  print(len(train_samples))\r\n",
        "  for sample in train_samples[:3]:\r\n",
        "    print(sample.replace(\"\\n\", \"\"))\r\n",
        "\r\n",
        "print(\"\\nVAL samples: \", end=\"\")\r\n",
        "with open(drive_path + \"val_samples.txt\") as f:\r\n",
        "  val_samples = f.readlines()\r\n",
        "  print(len(val_samples))\r\n",
        "  for sample in val_samples[:3]:\r\n",
        "    print(sample.replace(\"\\n\", \"\"))\r\n",
        "\r\n",
        "print(\"\\nTEST samples: \", end=\"\")\r\n",
        "with open(drive_path + \"test_samples.txt\") as f:\r\n",
        "  test_samples = f.readlines()\r\n",
        "  print(len(test_samples))\r\n",
        "  for sample in test_samples[:3]:\r\n",
        "    print(sample.replace(\"\\n\", \"\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TRAIN samples: 74520\n",
            "[CTX] Pain is a distressing feeling often caused by intense or damaging stimuli, such as stubbing a toe, burning a finger, putting alcohol on a cut, and bumping the \"funny bone\". Because it is a complex, subjective phenomenon, defining pain has been a challenge. The International Association for the Study of Pain's widely used definition states: \"Pain is an unpleasant sensory and emotional experience associated with actual or potential tissue damage, or described in terms of such damage.\" In medical diagnosis, pain is a symptom. [QS] What type of stimuli causes pain? [QE]\n",
            "[CTX] Pain is a distressing feeling often caused by intense or damaging stimuli, such as stubbing a toe, burning a finger, putting alcohol on a cut, and bumping the \"funny bone\". Because it is a complex, subjective phenomenon, defining pain has been a challenge. The International Association for the Study of Pain's widely used definition states: \"Pain is an unpleasant sensory and emotional experience associated with actual or potential tissue damage, or described in terms of such damage.\" In medical diagnosis, pain is a symptom. [QS] What type of feeling is pain? [QE]\n",
            "[CTX] Pain is a distressing feeling often caused by intense or damaging stimuli, such as stubbing a toe, burning a finger, putting alcohol on a cut, and bumping the \"funny bone\". Because it is a complex, subjective phenomenon, defining pain has been a challenge. The International Association for the Study of Pain's widely used definition states: \"Pain is an unpleasant sensory and emotional experience associated with actual or potential tissue damage, or described in terms of such damage.\" In medical diagnosis, pain is a symptom. [QS] Why has defining pain been a challenge? [QE]\n",
            "\n",
            "VAL samples: 12898\n",
            "[CTX] If a defendant is sentenced to death at the trial level, the case then goes into a direct review. The direct review process is a typical legal appeal. An appellate court examines the record of evidence presented in the trial court and the law that the lower court applied and decides whether the decision was legally sound or not. Direct review of a capital sentencing hearing will result in one of three outcomes. If the appellate court finds that no significant legal errors occurred in the capital sentencing hearing, the appellate court will affirm the judgment, or let the sentence stand. If the appellate court finds that significant legal errors did occur, then it will reverse the judgment, or nullify the sentence and order a new capital sentencing hearing. Lastly, if the appellate court finds that no reasonable juror could find the defendant eligible for the death penalty, a rarity, then it will order the defendant acquitted, or not guilty, of the crime for which he/she was given the death penalty, and order him sentenced to the next most severe punishment for which the offense is eligible. About 60 percent survive the process of direct review intact. [QS] What process begins after a death sentence is handed down at trial? [QE]\n",
            "[CTX] If a defendant is sentenced to death at the trial level, the case then goes into a direct review. The direct review process is a typical legal appeal. An appellate court examines the record of evidence presented in the trial court and the law that the lower court applied and decides whether the decision was legally sound or not. Direct review of a capital sentencing hearing will result in one of three outcomes. If the appellate court finds that no significant legal errors occurred in the capital sentencing hearing, the appellate court will affirm the judgment, or let the sentence stand. If the appellate court finds that significant legal errors did occur, then it will reverse the judgment, or nullify the sentence and order a new capital sentencing hearing. Lastly, if the appellate court finds that no reasonable juror could find the defendant eligible for the death penalty, a rarity, then it will order the defendant acquitted, or not guilty, of the crime for which he/she was given the death penalty, and order him sentenced to the next most severe punishment for which the offense is eligible. About 60 percent survive the process of direct review intact. [QS] In a direct review, what type of court looks at the record? [QE]\n",
            "[CTX] If a defendant is sentenced to death at the trial level, the case then goes into a direct review. The direct review process is a typical legal appeal. An appellate court examines the record of evidence presented in the trial court and the law that the lower court applied and decides whether the decision was legally sound or not. Direct review of a capital sentencing hearing will result in one of three outcomes. If the appellate court finds that no significant legal errors occurred in the capital sentencing hearing, the appellate court will affirm the judgment, or let the sentence stand. If the appellate court finds that significant legal errors did occur, then it will reverse the judgment, or nullify the sentence and order a new capital sentencing hearing. Lastly, if the appellate court finds that no reasonable juror could find the defendant eligible for the death penalty, a rarity, then it will order the defendant acquitted, or not guilty, of the crime for which he/she was given the death penalty, and order him sentenced to the next most severe punishment for which the offense is eligible. About 60 percent survive the process of direct review intact. [QS] How many possible outcomes are there of a capital sentencing direct review? [QE]\n",
            "\n",
            "TEST samples: 181\n",
            "[CTX] The city of Bern or Berne (German: Bern, pronounced [b…õrn] ( listen); French: Berne [b…õ Ån]; Italian: Berna [Ààb…õrna]; Romansh: Berna  [Ààb…õrn…ê] (help¬∑info); Bernese German: B√§rn [bÃ•√¶Àêrn]) is the de facto capital of Switzerland, referred to by the Swiss as their (e.g. in German) Bundesstadt, or \"federal city\".[note 1] With a population of 140,634 (November 2015), Bern is the fifth most populous city in Switzerland. The Bern agglomeration, which includes 36 municipalities, had a population of 406,900 in 2014. The metropolitan area had a population of 660,000 in 2000. Bern is also the capital of the Canton of Bern, the second most populous of Switzerland's cantons. [QS] What city is the de facto capital of Switserland?  [QE]\n",
            "[CTX] The city of Bern or Berne (German: Bern, pronounced [b…õrn] ( listen); French: Berne [b…õ Ån]; Italian: Berna [Ààb…õrna]; Romansh: Berna  [Ààb…õrn…ê] (help¬∑info); Bernese German: B√§rn [bÃ•√¶Àêrn]) is the de facto capital of Switzerland, referred to by the Swiss as their (e.g. in German) Bundesstadt, or \"federal city\".[note 1] With a population of 140,634 (November 2015), Bern is the fifth most populous city in Switzerland. The Bern agglomeration, which includes 36 municipalities, had a population of 406,900 in 2014. The metropolitan area had a population of 660,000 in 2000. Bern is also the capital of the Canton of Bern, the second most populous of Switzerland's cantons. [QS]  What is the second most populous of Switzerland's cantons? [QE]\n",
            "[CTX] The city of Bern or Berne (German: Bern, pronounced [b…õrn] ( listen); French: Berne [b…õ Ån]; Italian: Berna [Ààb…õrna]; Romansh: Berna  [Ààb…õrn…ê] (help¬∑info); Bernese German: B√§rn [bÃ•√¶Àêrn]) is the de facto capital of Switzerland, referred to by the Swiss as their (e.g. in German) Bundesstadt, or \"federal city\".[note 1] With a population of 140,634 (November 2015), Bern is the fifth most populous city in Switzerland. The Bern agglomeration, which includes 36 municipalities, had a population of 406,900 in 2014. The metropolitan area had a population of 660,000 in 2000. Bern is also the capital of the Canton of Bern, the second most populous of Switzerland's cantons. [QS] Which canton is Berne the capital? [QE]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUoA29-EdZ5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a52119c-9932-42b4-cafd-a52e460db4b5"
      },
      "source": [
        "def load_dataset(train_path, val_path, test_path, tokenizer):\r\n",
        "    print(\"Creating textdataset for Train...\", end=\"\")\r\n",
        "    train_dataset = TextDataset(\r\n",
        "          tokenizer=tokenizer,\r\n",
        "          file_path=drive_path + train_path,\r\n",
        "          block_size=128)\r\n",
        "    print(\"done.\\nCreating textdataset for Validation...\", end=\"\")\r\n",
        "    val_dataset = TextDataset(\r\n",
        "          tokenizer=tokenizer,\r\n",
        "          file_path=drive_path + val_path,\r\n",
        "          block_size=128)\r\n",
        "    print(\"done.\\nCreating textdataset for Test...\", end=\"\")\r\n",
        "    test_dataset = TextDataset(\r\n",
        "          tokenizer=tokenizer,\r\n",
        "          file_path=drive_path + test_path,\r\n",
        "          block_size=128)   \r\n",
        "    print(\"done.\")\r\n",
        "    data_collator = DataCollatorForLanguageModeling(\r\n",
        "        tokenizer=tokenizer, mlm=False,\r\n",
        "    )\r\n",
        "    return train_dataset, val_dataset, test_dataset, data_collator\r\n",
        "\r\n",
        "# load datasets from drive\r\n",
        "train_text, val_text, test_text, data_collator = load_dataset(\"train_samples.txt\", \"val_samples.txt\", \"test_samples.txt\", tokenizer)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating textdataset for Train..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (13660468 > 1024). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done.\n",
            "Creating textdataset for Validation...done.\n",
            "Creating textdataset for Test...done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh0pKsyPo4Et"
      },
      "source": [
        "## Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTSh14DlfAmE",
        "outputId": "c1f65b75-fef0-49bd-c9d2-83f2266cce3d"
      },
      "source": [
        "if LOAD_FROM_DRIVE:\r\n",
        "  MODEL_PATH = drive_path + MODEL_NAME\r\n",
        "\r\n",
        "print(\"Model selected:\", MODEL_PATH)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model selected: /content/drive/My Drive/SQUAD/QGen/GTP2_SQUAD_QGEN_3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT2lpd__o6sI"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51EhC01CoRg_"
      },
      "source": [
        "if not LOAD_FROM_DRIVE: \r\n",
        "  training_args = TrainingArguments(\r\n",
        "    output_dir = MODEL_NAME, # The output directory\r\n",
        "    overwrite_output_dir=True, # overwrite the content of the output directory\r\n",
        "    num_train_epochs = EPOCHS, # number of training epochs\r\n",
        "    per_device_train_batch_size = 32, # batch size for training\r\n",
        "    per_device_eval_batch_size = 64,  # batch size for evaluation\r\n",
        "    eval_steps = 5000, # Number of update steps between two evaluations.\r\n",
        "    save_steps = 5000, # after # steps model is saved \r\n",
        "    )\r\n",
        "\r\n",
        "  trainer = Trainer(\r\n",
        "      model=model,\r\n",
        "      args=training_args,\r\n",
        "      data_collator=data_collator,\r\n",
        "      train_dataset=train_text,\r\n",
        "      eval_dataset=val_text,\r\n",
        "      #prediction_loss_only=True,\r\n",
        "  )\r\n",
        "\r\n",
        "  trainer.train()\r\n",
        "  trainer.save_model()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa4sMS1vG038"
      },
      "source": [
        " Save model on drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq5x2ggQtfGn"
      },
      "source": [
        "if not LOAD_FROM_DRIVE: \r\n",
        "  import shutil\r\n",
        "  print(\"Copying on Drive...\")\r\n",
        "  drive_dest = f\"{drive_path}{MODEL_NAME}\"\r\n",
        "  shutil.copytree(MODEL_NAME, drive_dest)\r\n",
        "  print(f\"Model saved on drive at \\t{drive_dest}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3y0llUUegCV"
      },
      "source": [
        "## Question generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-OPpaC4pNGE"
      },
      "source": [
        "text_generator = pipeline('text-generation', model=MODEL_PATH, tokenizer=tokenizer, config={'max_length':100})"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2FTJ1mjyTST"
      },
      "source": [
        "def paragraph(text, max_width=80):\r\n",
        "  if len(text) > max_width:\r\n",
        "    cut = max_width\r\n",
        "    while text[cut] != \" \": cut -= 1\r\n",
        "    return text[:cut].strip() + \"\\n\" + paragraph(text[cut:], max_width)\r\n",
        "  else:\r\n",
        "    return text.strip()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOETN5wCpclv"
      },
      "source": [
        "test = np.array(test_samples)[:]\r\n",
        "true_questions = {}\r\n",
        "\r\n",
        "for t in test:\r\n",
        "  # separate context and questions\r\n",
        "  question_start = t.index(\"[QS]\") + 4\r\n",
        "  context, question = t[:question_start], t[question_start:]\r\n",
        "  # initualize dict key\r\n",
        "  if context not in true_questions: true_questions[context] = []\r\n",
        "  # add true question for the context\r\n",
        "  question = question.replace(\"[QE]\", \"\").replace(\"\\n\", \"\")\r\n",
        "  true_questions[context].append(question)\r\n",
        "\r\n",
        "contexts = list(true_questions.keys())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "O0bUCjdR5hF1",
        "outputId": "3f113489-a00b-4020-f574-bb39a8854f9e"
      },
      "source": [
        "contexts[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CTX] The city of Bern or Berne (German: Bern, pronounced [b…õrn] ( listen); French: Berne [b…õ Ån]; Italian: Berna [Ààb…õrna]; Romansh: Berna  [Ààb…õrn…ê] (help¬∑info); Bernese German: B√§rn [bÃ•√¶Àêrn]) is the de facto capital of Switzerland, referred to by the Swiss as their (e.g. in German) Bundesstadt, or \"federal city\".[note 1] With a population of 140,634 (November 2015), Bern is the fifth most populous city in Switzerland. The Bern agglomeration, which includes 36 municipalities, had a population of 406,900 in 2014. The metropolitan area had a population of 660,000 in 2000. Bern is also the capital of the Canton of Bern, the second most populous of Switzerland\\'s cantons. [QS]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auid7YrapgBs"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from datetime import datetime\r\n",
        "\r\n",
        "tf.get_logger().setLevel(\"ERROR\")\r\n",
        "transformers.logging.set_verbosity_error()\r\n",
        "\r\n",
        "samples_outputs = []\r\n",
        "for i in range(QUESTIONS_PER_CONTEXT):\r\n",
        "  print(f\"[{datetime.now().strftime('%H:%M:%S')}] Generated questions for each context: ({len(contexts[:N_CONTEXT_GEN])}) \", end=\"\")\r\n",
        "  print(f\"{i+1}/{QUESTIONS_PER_CONTEXT}\")\r\n",
        "  generation = text_generator(\r\n",
        "      contexts[:N_CONTEXT_GEN],\r\n",
        "      do_sample=True,\r\n",
        "      max_length=250,\r\n",
        "      top_k=50,\r\n",
        "      top_p=0.95,\r\n",
        "      num_return_sequences=1,\r\n",
        "      verbose=True\r\n",
        "  )\r\n",
        "  samples_outputs.append(generation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsYhJJWZLGIE"
      },
      "source": [
        "def clean(text):\r\n",
        "  return (text.\r\n",
        "          replace(\"[CTX]\", \"\").\r\n",
        "          replace(\"[QS]\", \"\").\r\n",
        "          replace(\"[QE]\", \"\").\r\n",
        "          strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlIdIFdZBVzM"
      },
      "source": [
        "pred_questions = {}\r\n",
        "count = 0\r\n",
        "bad_generations = 0\r\n",
        "for output in samples_outputs:\r\n",
        "  for batch in output:\r\n",
        "    for gen_text in batch:\r\n",
        "      text = gen_text[\"generated_text\"]\r\n",
        "      try:\r\n",
        "        q_start = text.index(\"[QS]\") + 4\r\n",
        "        q_end = text.index(\"[QE]\")\r\n",
        "        context = text[:q_start].replace(\"[QE]\", \"\")\r\n",
        "        pred_question = text[q_start : q_end]\r\n",
        "        if context not in pred_questions: pred_questions[context] = []\r\n",
        "        pred_questions[context].append(pred_question)\r\n",
        "        count += 1\r\n",
        "      except:\r\n",
        "       bad_generations += 1\r\n",
        "      \r\n",
        "print(pred_questions)\r\n",
        "print(f\"Expected questions: \\t{QUESTIONS_PER_CONTEXT*len(contexts[:N_CONTEXT_GEN])} \\t({QUESTIONS_PER_CONTEXT} questions for each {len(contexts[:N_CONTEXT_GEN])} context)\")\r\n",
        "print(f\"Well formed ones: \\t{count}\")\r\n",
        "print(f\"Bad formed ones: \\t{bad_generations}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckO2_CDR5GxG"
      },
      "source": [
        "# remove all tags\r\n",
        "context_question_dict = {}\r\n",
        "\r\n",
        "for context in pred_questions:\r\n",
        "  print(\"\\nContext: \\n\", paragraph(clean(context)), \"\\n\")\r\n",
        "\r\n",
        "  print(\"True questions: \")\r\n",
        "  for true in true_questions[context]:\r\n",
        "    print(\"-\", clean(true))\r\n",
        "\r\n",
        "  print(\"\\nPred questions: \")\r\n",
        "  for pred in pred_questions[context]:\r\n",
        "    print(\"-\", clean(pred))\r\n",
        "    context_question_dict.setdefault(clean(context), []).append(\r\n",
        "      clean(pred)\r\n",
        "    )\r\n",
        "\r\n",
        "  \r\n",
        "  print(\"=\"*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y59vgv7Plrlu"
      },
      "source": [
        "context_question_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbztxemcnDtV"
      },
      "source": [
        "#Saving results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaGp8Ir5xi3w"
      },
      "source": [
        "import json, shutil\r\n",
        "\r\n",
        "results_filename = f\"{count}_generated_questions.json\"\r\n",
        "with open(results_filename, \"w\") as f:\r\n",
        "  json.dump(context_question_dict, f)\r\n",
        "  print(\"Resulst saved.\")\r\n",
        "\r\n",
        "shutil.copy(results_filename, \"/content/drive/My Drive/SQUAD/\"+results_filename)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_3zamSZnUP5"
      },
      "source": [
        "##Dump to SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iIXbVlJnVtv"
      },
      "source": [
        "with open(results_filename) as f:\r\n",
        "  data = json.load(f)\r\n",
        "\r\n",
        "id_to_context = dict(enumerate(list(data.keys())))\r\n",
        "id_to_context\r\n",
        "context_to_id = {id_to_context[key]:key for key in id_to_context}\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWVzrvXbnd5R"
      },
      "source": [
        "# DUMP TABELLA CONTESTI\r\n",
        "i = 0\r\n",
        "sql_table_contesti = \"insert into contesti (testo, sondaggi) values\"\r\n",
        "for id in id_to_context:\r\n",
        "  testo = id_to_context[id].replace('\"', '\\\\\"')\r\n",
        "  sql_table_contesti += f'\\n(\"{testo}\", 0),'\r\n",
        "  i += 1\r\n",
        "  \r\n",
        "sql_table_contesti = sql_table_contesti[:-1]\r\n",
        "print(sql_table_contesti)\r\n",
        "\r\n",
        "with open(\"dump_table_contesti.sql\", \"w\") as f:\r\n",
        "  f.write(sql_table_contesti)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VYnWNk3yTqS"
      },
      "source": [
        "# DUMP TABELLA DOMANDE\r\n",
        "context_to_question = {context_to_id[context]: data[context] for context in data}\r\n",
        "context_to_question\r\n",
        "\r\n",
        "sql_table_domande = \"insert into domande (id_contesto, testo) values\"\r\n",
        "for context_id in context_to_question:\r\n",
        "  for question in context_to_question[context_id]:\r\n",
        "    testo = question.replace('\"', '\\\\\"')\r\n",
        "    sql_table_domande += f'\\n({context_id}, \"{testo}\"),'\r\n",
        "\r\n",
        "sql_table_domande = sql_table_domande[:-1]\r\n",
        "print(sql_table_domande)\r\n",
        "\r\n",
        "with open(\"dump_table_domande.sql\", \"w\") as f:\r\n",
        "  f.write(sql_table_domande)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}